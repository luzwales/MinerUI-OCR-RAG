"""
MinerU Tianshu - API Server
å¤©æ¢ API æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
æä¾› RESTful API æ¥å£ç”¨äºä»»åŠ¡æäº¤ã€æŸ¥è¯¢å’Œç®¡ç†
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import tempfile
from pathlib import Path
from loguru import logger
import uvicorn
from typing import Optional
from datetime import datetime
import os
import sys
import re
import uuid
from minio import Minio
import RAG.rag as rag  # æ–°å¢ï¼šå¯¼å…¥ RAG æ¨¡å—
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'rag')))
from config import Config  # å¯¼å…¥é…ç½®æ–‡ä»¶

import torch
from transformers import AutoModel, AutoTokenizer
from PIL import Image
import uvicorn
from decouple import config as env_config


from task_db import TaskDB

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="Flex AI API",
    description="Flex MinerU Tianshu - AI data preprocessing platform for documents, images, audio, and video.",
    version="1.0.0",
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
db = TaskDB()

# é…ç½®è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(Config.ocr_output_dir)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# MinIO é…ç½®
MINIO_CONFIG = {
    "endpoint": os.getenv("MINIO_ENDPOINT", ""),
    "access_key": os.getenv("MINIO_ACCESS_KEY", ""),
    "secret_key": os.getenv("MINIO_SECRET_KEY", ""),
    "secure": True,
    "bucket_name": os.getenv("MINIO_BUCKET", ""),
}


def get_minio_client():
    """è·å–MinIOå®¢æˆ·ç«¯å®ä¾‹"""
    return Minio(
        MINIO_CONFIG["endpoint"],
        access_key=MINIO_CONFIG["access_key"],
        secret_key=MINIO_CONFIG["secret_key"],
        secure=MINIO_CONFIG["secure"],
    )


def process_markdown_images(md_content: str, image_dir: Path, upload_images: bool = False):
    """
    å¤„ç† Markdown ä¸­çš„å›¾ç‰‡å¼•ç”¨

    Args:
        md_content: Markdown å†…å®¹
        image_dir: å›¾ç‰‡æ‰€åœ¨ç›®å½•
        upload_images: æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢é“¾æ¥

    Returns:
        å¤„ç†åçš„ Markdown å†…å®¹
    """
    if not upload_images:
        return md_content

    try:
        minio_client = get_minio_client()
        bucket_name = MINIO_CONFIG["bucket_name"]
        minio_endpoint = MINIO_CONFIG["endpoint"]

        # æŸ¥æ‰¾æ‰€æœ‰ markdown æ ¼å¼çš„å›¾ç‰‡
        img_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"

        def replace_image(match):
            alt_text = match.group(1)
            image_path = match.group(2)

            # æ„å»ºå®Œæ•´çš„æœ¬åœ°å›¾ç‰‡è·¯å¾„
            full_image_path = image_dir / Path(image_path).name

            if full_image_path.exists():
                # è·å–æ–‡ä»¶åç¼€
                file_extension = full_image_path.suffix
                # ç”Ÿæˆ UUID ä½œä¸ºæ–°æ–‡ä»¶å
                new_filename = f"{uuid.uuid4()}{file_extension}"

                try:
                    # ä¸Šä¼ åˆ° MinIO
                    object_name = f"images/{new_filename}"
                    minio_client.fput_object(bucket_name, object_name, str(full_image_path))

                    # ç”Ÿæˆ MinIO è®¿é—® URL
                    scheme = "https" if MINIO_CONFIG["secure"] else "http"
                    minio_url = f"{scheme}://{minio_endpoint}/{bucket_name}/{object_name}"

                    # è¿”å› HTML æ ¼å¼çš„ img æ ‡ç­¾
                    return f'<img src="{minio_url}" alt="{alt_text}">'
                except Exception as e:
                    logger.error(f"Failed to upload image to MinIO: {e}")
                    return match.group(0)  # ä¸Šä¼ å¤±è´¥ï¼Œä¿æŒåŸæ ·

            return match.group(0)

        # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
        new_content = re.sub(img_pattern, replace_image, md_content)
        return new_content

    except Exception as e:
        logger.error(f"Error processing markdown images: {e}")
        return md_content  # å‡ºé”™æ—¶è¿”å›åŸå†…å®¹


@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "service": "Flex MinerU Tianshu API",
        "version": "1.0.0",
        "description": "Flex MinerU Tianshu - AI data preprocessing platform",
        "features": "Document, Image, Audio, Video processing with OCR and RAG capabilities",
        "docs": "/docs",
    }


@app.post("/api/v1/tasks/submit")
async def submit_task(
    file: UploadFile = File(..., description="Document: PDF/Picture/Office/HTML/Audio/Video ect."),
    backend: str = Form(
        "pipeline", description="Handling: pipeline/deepseek-ocr/paddleocr-vl (Document) | sensevoice (Audio) | video "
    ),
    lang: str = Form("auto", description="Language: auto/ch/en/korean/japanç­‰"),
    method: str = Form("auto", description="example: auto/txt/ocr"),
    formula_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«"),
    table_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«"),
    priority: int = Form(0, description="ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆ"),
    # DeepSeek OCR ä¸“ç”¨å‚æ•°
    deepseek_resolution: str = Form("base", description="DeepSeek OCR åˆ†è¾¨ç‡: tiny/small/base/large/dynamic"),
    deepseek_prompt_type: str = Form("document", description="DeepSeek OCR æç¤ºè¯ç±»å‹: document/image/free/figure"),
    # è§†é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    keep_audio: bool = Form(False, description="è§†é¢‘å¤„ç†æ—¶æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘æ–‡ä»¶"),
    enable_keyframe_ocr: bool = Form(False, description="æ˜¯å¦å¯ç”¨è§†é¢‘å…³é”®å¸§OCRè¯†åˆ«ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰"),
    ocr_backend: str = Form("paddleocr-vl", description="å…³é”®å¸§OCRå¼•æ“: paddleocr-vl/deepseek-ocr"),
    keep_keyframes: bool = Form(False, description="æ˜¯å¦ä¿ç•™æå–çš„å…³é”®å¸§å›¾åƒ"),
    # æ°´å°å»é™¤ä¸“ç”¨å‚æ•°
    remove_watermark: bool = Form(False, description="æ˜¯å¦å¯ç”¨æ°´å°å»é™¤ï¼ˆæ”¯æŒ PDF/å›¾ç‰‡ï¼‰"),
    watermark_conf_threshold: float = Form(0.35, description="æ°´å°æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œæ¨è 0.35ï¼‰"),
    watermark_dilation: int = Form(10, description="æ°´å°æ©ç è†¨èƒ€å¤§å°ï¼ˆåƒç´ ï¼Œæ¨è 10ï¼‰"),
):
    """
    æäº¤æ–‡æ¡£è§£æä»»åŠ¡

    ç«‹å³è¿”å› task_idï¼Œä»»åŠ¡åœ¨åå°å¼‚æ­¥å¤„ç†
    """
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix)

        # æµå¼å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜ï¼Œé¿å…é«˜å†…å­˜ä½¿ç”¨
        while True:
            chunk = await file.read(1 << 23)  # 8MB chunks
            if not chunk:
                break
            temp_file.write(chunk)

        temp_file.close()

        # åˆ›å»ºä»»åŠ¡
        task_id = db.create_task(
            file_name=file.filename,
            file_path=temp_file.name,
            backend=backend,
            options={
                "lang": lang,
                "method": method,
                "formula_enable": formula_enable,
                "table_enable": table_enable,
                # DeepSeek OCR å‚æ•°
                "deepseek_resolution": deepseek_resolution,
                "deepseek_prompt_type": deepseek_prompt_type,
                # è§†é¢‘å¤„ç†å‚æ•°
                "keep_audio": keep_audio,
                "enable_keyframe_ocr": enable_keyframe_ocr,
                "ocr_backend": ocr_backend,
                "keep_keyframes": keep_keyframes,
                # æ°´å°å»é™¤å‚æ•°
                "remove_watermark": remove_watermark,
                "watermark_conf_threshold": watermark_conf_threshold,
                "watermark_dilation": watermark_dilation,
            },
            priority=priority,
        )

        logger.info(f"âœ… Task submitted: {task_id} - {file.filename}")
        logger.info(f"   Backend: {backend}")
        logger.info(f"   Priority: {priority}")
        if backend == "deepseek-ocr":
            logger.info(f"   DeepSeek Resolution: {deepseek_resolution}")
            logger.info(f"   DeepSeek Prompt Type: {deepseek_prompt_type}")

        return {
            "success": True,
            "task_id": task_id,
            "status": "pending",
            "message": "Task submitted successfully",
            "file_name": file.filename,
            "created_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks/{task_id}")
async def get_task_status(
    task_id: str,
    upload_images: bool = Query(False, description="æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ°MinIOå¹¶æ›¿æ¢é“¾æ¥ï¼ˆä»…å½“ä»»åŠ¡å®Œæˆæ—¶æœ‰æ•ˆï¼‰"),
    format: str = Query("markdown", description="è¿”å›æ ¼å¼: markdown(é»˜è®¤)/json/both"),
):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œè¯¦æƒ…

    å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä¼šè‡ªåŠ¨è¿”å›è§£æåçš„å†…å®¹ï¼ˆdata å­—æ®µï¼‰
    - format=markdown: åªè¿”å› Markdown å†…å®¹ï¼ˆé»˜è®¤ï¼‰
    - format=json: åªè¿”å› JSON ç»“æ„åŒ–æ•°æ®ï¼ˆMinerU å’Œ PaddleOCR-VL æ”¯æŒï¼‰
    - format=both: åŒæ—¶è¿”å› Markdown å’Œ JSON
    å¯é€‰æ‹©æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢ä¸º URL
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    response = {
        "success": True,
        "task_id": task_id,
        "status": task["status"],
        "file_name": task["file_name"],
        "backend": task["backend"],
        "priority": task["priority"],
        "error_message": task["error_message"],
        "created_at": task["created_at"],
        "started_at": task["started_at"],
        "completed_at": task["completed_at"],
        "worker_id": task["worker_id"],
        "retry_count": task["retry_count"],
    }
    logger.info(f"âœ… Task status: {task['status']} - (result_path: {task['result_path']})")

    # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œå°è¯•è¿”å›è§£æå†…å®¹
    if task["status"] == "completed":
        if not task["result_path"]:
            # ç»“æœæ–‡ä»¶å·²è¢«æ¸…ç†
            response["data"] = None
            response["message"] = "Task completed but result files have been cleaned up (older than retention period)"
            return response

        result_dir = Path(task["result_path"])
        logger.info(f"ğŸ“‚ Checking result directory: {result_dir}")

        if result_dir.exists():
            logger.info("âœ… Result directory exists")
            # é€’å½’æŸ¥æ‰¾ Markdown æ–‡ä»¶ï¼ˆMinerU è¾“å‡ºç»“æ„ï¼štask_id/filename/auto/*.mdï¼‰
            md_files = list(result_dir.rglob("*.md"))
            # é€’å½’æŸ¥æ‰¾ JSON æ–‡ä»¶ (æ’é™¤è°ƒè¯•ç”¨çš„ page_*.json)
            json_files = [
                f
                for f in result_dir.rglob("*.json")
                if not f.parent.name.startswith("page_") and f.name in ["content.json", "result.json"]
            ]
            logger.info(f"ğŸ“„ Found {len(md_files)} markdown files and {len(json_files)} json files")

            if md_files:
                try:
                    # åˆå§‹åŒ– data å­—æ®µ
                    response["data"] = {}

                    # æ ‡è®° JSON æ˜¯å¦å¯ç”¨
                    response["data"]["json_available"] = len(json_files) > 0

                    # æ ¹æ® format å‚æ•°å†³å®šè¿”å›å†…å®¹
                    if format in ["markdown", "both"]:
                        # è¯»å– Markdown å†…å®¹
                        md_file = md_files[0]
                        logger.info(f"ğŸ“– Reading markdown file: {md_file}")
                        with open(md_file, "r", encoding="utf-8") as f:
                            md_content = f.read()

                        logger.info(f"âœ… Markdown content loaded, length: {len(md_content)} characters")

                        # æŸ¥æ‰¾å›¾ç‰‡ç›®å½•ï¼ˆåœ¨ markdown æ–‡ä»¶çš„åŒçº§ç›®å½•ä¸‹ï¼‰
                        image_dir = md_file.parent / "images"

                        # å¤„ç†å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        if upload_images and image_dir.exists():
                            logger.info(f"ğŸ–¼ï¸  Processing images for task {task_id}, upload_images={upload_images}")
                            md_content = process_markdown_images(md_content, image_dir, upload_images)

                        # æ·»åŠ  Markdown ç›¸å…³å­—æ®µ
                        response["data"]["markdown_file"] = md_file.name
                        response["data"]["content"] = md_content
                        response["data"]["images_uploaded"] = upload_images
                        response["data"]["has_images"] = image_dir.exists() if not upload_images else None

                    # å¦‚æœç”¨æˆ·è¯·æ±‚ JSON æ ¼å¼
                    if format in ["json", "both"] and json_files:
                        import json as json_lib

                        json_file = json_files[0]
                        logger.info(f"ğŸ“– Reading JSON file: {json_file}")
                        try:
                            with open(json_file, "r", encoding="utf-8") as f:
                                json_content = json_lib.load(f)
                            response["data"]["json_file"] = json_file.name
                            response["data"]["json_content"] = json_content
                            logger.info("âœ… JSON content loaded successfully")
                        except Exception as json_e:
                            logger.warning(f"âš ï¸  Failed to load JSON: {json_e}")
                    elif format == "json" and not json_files:
                        # ç”¨æˆ·è¯·æ±‚ JSON ä½†æ²¡æœ‰ JSON æ–‡ä»¶
                        logger.warning("âš ï¸  JSON format requested but no JSON file available")
                        response["data"]["message"] = "JSON format not available for this backend"

                    # å¦‚æœæ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹ï¼Œæ·»åŠ æç¤º
                    if not response["data"]:
                        response["data"] = None
                        logger.warning(f"âš ï¸  No data returned for format: {format}")
                    else:
                        logger.info(f"âœ… Response data field added successfully (format={format})")

                except Exception as e:
                    logger.error(f"âŒ Failed to read content: {e}")
                    logger.exception(e)
                    # è¯»å–å¤±è´¥ä¸å½±å“çŠ¶æ€æŸ¥è¯¢ï¼Œåªæ˜¯ä¸è¿”å› data
                    response["data"] = None
            else:
                logger.warning(f"âš ï¸  No markdown files found in {result_dir}")
        else:
            logger.error(f"âŒ Result directory does not exist: {result_dir}")
    elif task["status"] == "completed":
        logger.warning("âš ï¸  Task completed but result_path is empty")
    else:
        logger.info(f"â„¹ï¸  Task status is {task['status']}, skipping content loading")

    return response


@app.delete("/api/v1/tasks/{task_id}")
async def cancel_task(task_id: str):
    """
    å–æ¶ˆä»»åŠ¡ï¼ˆä»…é™ pending çŠ¶æ€ï¼‰
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    if task["status"] == "pending":
        db.update_task_status(task_id, "cancelled")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        file_path = Path(task["file_path"])
        if file_path.exists():
            file_path.unlink()

        logger.info(f"â¹ï¸  Task cancelled: {task_id}")
        return {"success": True, "message": "Task cancelled successfully"}
    else:
        raise HTTPException(status_code=400, detail=f"Cannot cancel task in {task['status']} status")


@app.get("/api/v1/queue/stats")
async def get_queue_stats():
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
    """
    stats = db.get_queue_stats()

    return {"success": True, "stats": stats, "total": sum(stats.values()), "timestamp": datetime.now().isoformat()}

# -----------------------------
# RAG REST æ¥å£ï¼ˆå°† Gradio æ›¿æ¢ä¸º FastAPI è·¯ç”±ï¼‰
# -----------------------------
@app.get("/api/kbs")
async def list_kbs():
    """åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“"""
    try:
        kbs = rag.get_knowledge_bases()
        return {"success": True, "kbs": kbs}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/kb")
async def create_kb(kb_name: str = Form(...)):
    """åˆ›å»ºçŸ¥è¯†åº“"""
    try:
        res = rag.create_knowledge_base(kb_name)
        return {"success": True, "message": res}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/kb/{kb_name}")
async def delete_kb(kb_name: str):
    """åˆ é™¤çŸ¥è¯†åº“"""
    try:
        res = rag.delete_knowledge_base(kb_name)
        return {"success": True, "message": res}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/kb/{kb_name}/files")
async def list_kb_files(kb_name: str):
    """åˆ—å‡ºæŒ‡å®šçŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶å’Œç´¢å¼•çŠ¶æ€"""
    try:
        files = rag.get_kb_files(kb_name)
        kb_dir = os.path.join(rag.KB_BASE_DIR, kb_name)
        has_index = os.path.exists(os.path.join(kb_dir, "semantic_chunk.index"))
        return {"success": True, "files": files, "has_index": has_index}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/kb/{kb_name}/upload")
async def upload_files_to_kb(kb_name: str, files: List[UploadFile] = File(...)):
    """
    ä¸Šä¼ å¤šä¸ªæ–‡ä»¶åˆ°æŒ‡å®šçŸ¥è¯†åº“å¹¶è¿›è¡Œå¤„ç†ï¼ˆæ”¯æŒ .txt å’Œ .pdfï¼‰
    æ–‡ä»¶ä¼šè¢«æš‚å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œä¼ ç»™ RAG æ¨¡å—å¤„ç†ï¼Œå¤„ç†å®Œæˆåä¸´æ—¶æ–‡ä»¶ä¼šè¢«æ¸…ç†ã€‚
    """
    tmp_paths = []
    try:
        if not files:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ–‡ä»¶")
        # ä¿å­˜æ¯ä¸ªä¸Šä¼ æ–‡ä»¶åˆ°ä¸´æ—¶è·¯å¾„
        for up in files:
            # ä¿æŒåŸå§‹åç¼€
            _, ext = os.path.splitext(up.filename or "")
            if not ext:
                ext = ".bin"
            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmpf:
                content = await up.read()
                tmpf.write(content)
                tmp_paths.append(tmpf.name)
        # è°ƒç”¨ rag æ¨¡å—è¿›è¡Œå¤„ç†ï¼ˆæ”¯æŒæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼‰
        result = rag.process_and_index_files(tmp_paths, kb_name)
        return {"success": True, "message": result}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for p in tmp_paths:
            try:
                os.remove(p)
            except Exception:
                pass

@app.post("/api/rag/ask")
async def rag_ask(
    question: str = Form(...),
    kb_name: str = Form(rag.DEFAULT_KB),
    use_search: bool = Form(True),
    use_table_format: bool = Form(False),
    multi_hop: bool = Form(False),
):
    """
    ä½¿ç”¨ RAG æ¨¡å—å›ç­”é—®é¢˜ï¼ˆåŒæ­¥æ¥å£ï¼‰
    - question: å¾…é—®é—®é¢˜
    - kb_name: ä½¿ç”¨çš„çŸ¥è¯†åº“
    - use_search: æ˜¯å¦å¯ç”¨è”ç½‘æœç´¢
    - use_table_format: æ˜¯å¦è¦æ±‚è¡¨æ ¼æ ¼å¼è¾“å‡º
    - multi_hop: æ˜¯å¦å¯ç”¨å¤šè·³æ¨ç†ï¼ˆå½“å‰ ask_question_parallel ä¼šæ ¹æ®å‚æ•°é€‰æ‹©ï¼‰
    """
    try:
        # ä½¿ç”¨ rag.ask_question_parallelï¼ˆå†…éƒ¨ä¼šæ ¹æ® multi_hop/use_search å†³å®šç­–ç•¥ï¼‰
        answer = rag.ask_question_parallel(question, kb_name=kb_name, use_search=use_search, use_table_format=use_table_format, multi_hop=multi_hop)
        return {"success": True, "answer": answer}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/queue/tasks")
async def list_tasks(
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€: pending/processing/completed/failed"),
    limit: int = Query(100, description="è¿”å›æ•°é‡é™åˆ¶", le=1000),
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨
    """
    if status:
        tasks = db.get_tasks_by_status(status, limit)
    else:
        # è¿”å›æ‰€æœ‰ä»»åŠ¡ï¼ˆéœ€è¦ä¿®æ”¹ TaskDB æ·»åŠ è¿™ä¸ªæ–¹æ³•ï¼‰
        with db.get_cursor() as cursor:
            cursor.execute(
                """
                SELECT * FROM tasks
                ORDER BY created_at DESC
                LIMIT ?
            """,
                (limit,),
            )
            tasks = [dict(row) for row in cursor.fetchall()]

    return {"success": True, "count": len(tasks), "tasks": tasks}


@app.post("/api/v1/admin/cleanup")
async def cleanup_old_tasks(days: int = Query(7, description="æ¸…ç†Nå¤©å‰çš„ä»»åŠ¡")):
    """
    æ¸…ç†æ—§ä»»åŠ¡è®°å½•ï¼ˆç®¡ç†æ¥å£ï¼‰
    """
    deleted_count = db.cleanup_old_tasks(days)

    logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks")

    return {"success": True, "deleted_count": deleted_count, "message": f"Cleaned up tasks older than {days} days"}


@app.post("/api/v1/admin/reset-stale")
async def reset_stale_tasks(timeout_minutes: int = Query(60, description="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")):
    """
    é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰
    """
    reset_count = db.reset_stale_tasks(timeout_minutes)

    logger.info(f"ğŸ”„ Reset {reset_count} stale tasks")

    return {
        "success": True,
        "reset_count": reset_count,
        "message": f"Reset tasks processing for more than {timeout_minutes} minutes",
    }


@app.get("/api/v1/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        stats = db.get_queue_stats()

        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": "connected",
            "queue_stats": stats,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(status_code=503, content={"status": "unhealthy", "error": str(e)})


if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£ï¼Œé»˜è®¤ä¸º8000
    api_port = int(os.getenv("API_PORT", "8000"))

    logger.info("ğŸš€ Starting Flex AI API Server...")
    logger.info(f"ğŸ“– API Documentation: http://localhost:{api_port}/docs")

    uvicorn.run(app, host="127.0.0.1", port=api_port, log_level="info")
